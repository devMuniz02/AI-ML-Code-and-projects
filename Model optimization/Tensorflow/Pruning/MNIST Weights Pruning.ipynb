{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02e75da-89df-449f-87ed-601534161cb3",
   "metadata": {},
   "source": [
    "Base model - NO PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821426d6-1141-457e-9b1a-d37d7a3eee19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization tf_keras\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tf_keras as keras\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n",
    "\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "# Clone the architecture\n",
    "base_model = clone_model(model)\n",
    "\n",
    "# Copy the weights\n",
    "base_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88aa7f4-feb0-4f48-a6dd-db626593d5ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b8655-dc96-4dcd-a38e-6a1b2df3fbe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee186d-536c-42a2-b5b2-c426f6fe706d",
   "metadata": {},
   "source": [
    "SPARCITY BASE MODEL VS. PRUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc20360-4093-438e-9a22-c0e22b8b73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()\n",
    "model_for_pruning.summary()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize sparsity in weights\n",
    "def visualize_sparsity(layer):\n",
    "    weights = layer.get_weights()[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f\"Sparsity in {layer.name}\")\n",
    "    plt.hist(weights.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.xlabel(\"Weight Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sparsity in the convolutional layers\n",
    "visualize_sparsity(base_model.get_layer(name='conv2d'))\n",
    "visualize_sparsity(model_for_pruning.get_layer(name='prune_low_magnitude_conv2d'))\n",
    "\n",
    "# Visualize sparsity in the dense layer\n",
    "visualize_sparsity(base_model.get_layer(name='dense'))\n",
    "visualize_sparsity(model_for_pruning.get_layer(name='prune_low_magnitude_dense'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa570e58-2d38-4343-8388-fbaccc088378",
   "metadata": {},
   "source": [
    "SAVING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f2da1-6978-4057-94b3-007c30eafb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "#%tensorboard --logdir={logdir}\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa82b5-9aa6-4feb-97e5-bc5c9511eb0c",
   "metadata": {},
   "source": [
    "SIZE OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5bf93-8015-4f1f-981a-e9ef23a93c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94277a88-3899-478e-8890-4ea69085b047",
   "metadata": {},
   "source": [
    "QUANTIZATION AND SIZE OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18e127-351d-4bc0-887b-206162d37767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01883923-aa26-420c-98ce-cf8d3245d08a",
   "metadata": {},
   "source": [
    "FINAL ACCURACY OF PRUNED VS. PRUNED + QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f874a-eabe-41d3-8a66-ce0daa375944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on ever y image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
