{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada7e1b3-ac8e-4723-902f-17801a50e0b8",
   "metadata": {},
   "source": [
    "BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108dbe1-f0ec-4d31-8cb0-a83ea6b1f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization tf_keras\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tf_keras as keras\n",
    "\n",
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a17d2-fdac-41cc-a2f6-4fc640c2a7c5",
   "metadata": {},
   "source": [
    "CLUSTERING BASE MODEL WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95f025-0f18-4c84-a770-c8057ac85e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()\n",
    "\n",
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)\n",
    "\n",
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  test_images, test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efe016-b6b6-481a-8413-3ddfdc36a9e4",
   "metadata": {},
   "source": [
    "ACCURACY BASE MODEL VS. CLUSTERED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b26497-f398-4c6a-8c55-5737997a9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dab66f-a425-4c4f-ae25-cd39499b9da9",
   "metadata": {},
   "source": [
    "SIZE BASE MODEL VS. CLUSTERED BASE MODEL VS. CLUSTERED TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980eb607-6210-4eb5-9e6c-38e8f5b983a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)\n",
    "\n",
    "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # It returns the size of the gzipped model in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
    "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0174b2-177f-46d8-ab51-913ce75c08e5",
   "metadata": {},
   "source": [
    "SIZE CLUSTERED TFLite VS. BASE MODEL VS. CLUSTERED + QUANT TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f06b4-92d1-4f3b-8026-28f8ebfd3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53083cde-179e-41e6-b482-873cc81c7f19",
   "metadata": {},
   "source": [
    "ACCURACY CLUSTERED TFLite VS. CLUSTERED + QUANT TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1171c-21d8-46cb-86bb-112b6ec54995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on ever y image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Clustered TF test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76339582-32fc-44cf-b9ae-cb66d6ebc6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
